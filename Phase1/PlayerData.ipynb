{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data üìâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_of_players(link, players_datas):\n",
    "    res = {}\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\", \"accept-language\": \"en-US,en;q=0.9\"}        \n",
    "    url = link\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    #Getting Players ID\n",
    "    pattern = r\"/(\\d+)$\"\n",
    "    match = re.search(pattern, url)\n",
    "    player_id = match.group(1)\n",
    "    res[\"player_id\"] = player_id\n",
    "\n",
    "    #Getting Given Name and Shirt Number\n",
    "    try:\n",
    "        header = soup.find(\"h1\", class_ = \"data-header__headline-wrapper\")\n",
    "        shirt_number = header.find(\"span\", class_ = \"data-header__shirt-number\").get_text(strip = True)\n",
    "        given_name = \" \".join(header.stripped_strings).replace(shirt_number, \"\").strip()\n",
    "    except AttributeError:\n",
    "        shirt_number = None\n",
    "        given_name = None\n",
    "    if given_name == None:\n",
    "        try:\n",
    "            given_name = soup.find(\"h1\", class_ = \"data-header__headline-wrapper\").text.strip()\n",
    "        except AttributeError:\n",
    "            given_name = None\n",
    "    res[\"shirt_number\"] = shirt_number\n",
    "    res[\"given_name\"] = given_name\n",
    "\n",
    "    #Getting Full Name\n",
    "    try:\n",
    "        full_name = soup.select_one(\"span.info-table__content.info-table__content--bold\").get_text(strip = True)\n",
    "        pattern = r\"\\d+\"\n",
    "        match = re.search(pattern, full_name)\n",
    "        if(bool(match)):\n",
    "            full_name = None\n",
    "    except AttributeError:\n",
    "        full_name = None\n",
    "    res[\"full_name\"] = full_name\n",
    "\n",
    "    #Getting Date Of Birth\n",
    "    try:\n",
    "        date_of_birth = soup.select_one(\"span.info-table__content.info-table__content--bold a[href^='/aktuell/waspassiertheute/aktuell/new/datum/']\").text.strip()\n",
    "    except AttributeError:\n",
    "        date_of_birth = None\n",
    "    res[\"date_of_birth\"] = date_of_birth\n",
    "\n",
    "    #Getting Citizenship\n",
    "    try:\n",
    "        citizenship = soup.select_one(\"li.data-header__label span[itemprop='nationality']\").get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        citizenship = None\n",
    "    res[\"citizenship\"] = citizenship\n",
    "\n",
    "    #Getting Place Of Birth\n",
    "    try:\n",
    "        place_of_birth = soup.select_one(\"li.data-header__label span.data-header__content[itemprop='birthPlace']\").get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        place_of_birth = None\n",
    "    res[\"place_of_birth\"] = place_of_birth\n",
    "\n",
    "    #Getting Caps and Goals\n",
    "    try:\n",
    "        caps = soup.select_one(\"li.data-header__label > a:nth-of-type(1).data-header__content--highlight\").get_text(strip = True)\n",
    "        goals = soup.select_one(\"li.data-header__label > a:nth-of-type(2).data-header__content--highlight\").get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        caps = None\n",
    "        goals = None\n",
    "    res[\"caps\"] = caps\n",
    "    res[\"goals\"] = goals\n",
    "\n",
    "    #Getting Player Agent\n",
    "    try:\n",
    "        agent = soup.select_one(\"li.data-header__label:contains('Agent') a\").get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        agent = None\n",
    "\n",
    "    #Getting Other Positions\n",
    "    try:\n",
    "        other_position_soup = soup.find(\"div\", class_ = \"detail-position__position\")\n",
    "        other_positions = [position.text.strip() for position in other_position_soup.find_all(\"dd\", class_ = \"detail-position__position\")]\n",
    "        other_positions = \", \".join(other_positions)\n",
    "    except AttributeError:\n",
    "        other_positions = None\n",
    "    res[\"other_positions\"] = other_positions\n",
    "\n",
    "    temp = soup.select(\"#main > main > div > div.large-8.columns > div > div > div.large-6.large-pull-6.small-12.columns.spielerdatenundfakten > div > span\")\n",
    "\n",
    "    outfitter = None\n",
    "    contract_expires = None\n",
    "    foot = None\n",
    "    contract_Joined = None\n",
    "    height = None\n",
    "    current_club = None\n",
    "    date_of_last_contract = None\n",
    "\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        #Getting Outfitter\n",
    "        if \"Outfitter\" in temp[i].text:\n",
    "            outfitter = temp[i+1].text.strip()\n",
    "        #Getting Contract Expires\n",
    "        elif \"Contract expires\" in temp[i].text:\n",
    "            contract_expires = temp[i+1].text.strip()\n",
    "        #Getting Agent\n",
    "        elif \"agent\" in temp[i].text and agent == None:\n",
    "            agent = temp[i+1].text.strip()\n",
    "        #Getting Foot\n",
    "        elif \"Foot\" in temp[i].text:\n",
    "            foot = temp[i+1].text.strip()\n",
    "        #Getting Joined\n",
    "        elif \"Joined\" in temp[i].text:\n",
    "            contract_Joined = temp[i+1].text.strip()\n",
    "        #Getting Height\n",
    "        elif \"Height\" in temp[i].text:\n",
    "            height = temp[i+1].text.strip()\n",
    "            height = str(\"\".join(filter(str.isdigit, height)))\n",
    "        #Getting Current Club\n",
    "        elif \"Current club\" in temp[i].text:\n",
    "            current_club = temp[i+1].text.strip()\n",
    "        #Getting last Contract\n",
    "        elif \"last contract\" in temp[i].text:\n",
    "            date_of_last_contract = temp[i+1].text.strip()\n",
    "\n",
    "    res[\"outfitter\"] = outfitter\n",
    "    res[\"contract_expires\"] = contract_expires\n",
    "    res[\"agent\"] = agent\n",
    "    res[\"foot\"] = foot\n",
    "    res[\"contract_Joined\"] = contract_Joined\n",
    "    res[\"height\"] = height\n",
    "    res[\"current_club\"] = current_club\n",
    "    res[\"date_of_last_contract\"] = date_of_last_contract\n",
    "\n",
    "    players_link = link\n",
    "    res[\"players_link\"] = players_link\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_datas = pd.DataFrame({\"player_id\" : [], \"shirt_number\" : [], \"given_name\" : [], \"full_name\" : [], \"date_of_birth\" : [],\n",
    "                        \"citizenship\" : [], \"place_of_birth\" : [], \"caps\" : [], \"goals\" : [], \"other_positions\" : [], \"outfitter\" : [], \"contract_expires\" : [],\n",
    "                        \"agent\" : [], \"foot\" : [], \"contract_Joined\" : [], \"height\" : [], \"current_club\" : [], \"date_of_last_contract\" : [], \"players_link\" : []})\n",
    "players_datas = players_datas.astype(str)\n",
    "links = pd.read_csv(\"All_players_links.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data üë©‚Äçüíªüë®‚Äçüíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(links)):\n",
    "    res = data_of_players(links.loc[i, \"0\"], players_datas)\n",
    "    players_datas = players_datas.append(res, ignore_index = True)\n",
    "\n",
    "pd.DataFrame(players_datas).to_csv(\"All_players_datas.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
